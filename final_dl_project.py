# -*- coding: utf-8 -*-
"""final dl project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1weG9T8BGdn-35GM6up-UbcPM0b6uM1mH
"""

import pandas as pd

data=pd.read_csv(r"/content/drive/MyDrive/dl pro video/train.csv")
data

data.isnull().sum()

"""**REMOVING NULL VALUES**"""

data=data.dropna() #we are dropping as this is a text data we cant replace with anything like numerics

x=data.drop("label",axis=1)

x.shape

y=data['label']

y.shape

"""**IMPORT DEPENDENCIES OF LSTM MODEL**"""

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense

voc_size=5000

message=x["title"]

message[1]

message[15]

"""**TEXT PREPROCESSING**"""

import nltk
import re
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')

from nltk.stem.porter import PorterStemmer ##stemming purpose
ps = PorterStemmer()
corpus = []
for i in message:
    review = re.sub('[^a-zA-Z]', ' ',i).lower().split()
    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]
    review = ' '.join(review)
    corpus.append(review)

"""**ONE HOT ENCODING**"""

onehot_repr=[one_hot(words,voc_size)for words in corpus]
onehot_repr

sent_length=15
embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)
print(embedded_docs)

"""**CREATING MODEL**"""

features=30#features representation
model=Sequential()
model.add(Embedding(voc_size,features,input_length=sent_length))
model.add(LSTM(100))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
print(model.summary())

import numpy as np

import numpy as np
X_final=np.array(embedded_docs)
y_final=np.array(y)

"""**SPLITTING TRAIN AND TEST**"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)

model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=100)

y_pred=model.predict(X_test)
y_pred

y_pred=np.where(y_pred > 0.6, 1,0)
y_pred

"""**ACCCURACY SCORE**"""

from sklearn.metrics import accuracy_score
print("Accuracy Score:",accuracy_score(y_test,y_pred))

model.save("model.h5")